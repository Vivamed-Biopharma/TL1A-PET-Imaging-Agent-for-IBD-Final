# TL1A In-Silico Panel
- Program: anti-TL1A Fab panel for Ga-68 NOTA PET imaging in IBD.
- Scope: 12 germline-based Fab seeds + 100+ conservative CDR variants with developability, conjugation, detectability, and immunogenicity heuristics.
- Primary output: `REPORT.md` (sponsor-style narrative) with synchronized CSV/PNG artifacts produced by `report.py`.

## 1. Quick Start
- Install Python 3.10+ and follow `00_env/README.md` for either the minimal or RDKit-enabled environment.
- Activate the environment and run `python report.py` from the repo root to rebuild every CSV, FASTA, and figure before re-reading `REPORT.md`.
- Optional: launch notebooks (`jupyter notebook`) to step through the numbered workflows after the environment is in place.

Environment toggles (no code edits needed):
- `TL1A_VARIANTS` (default `120`) — number of enumerated CDR variants.
- `TL1A_SEED` (default `1337`) — RNG seed for reproducibility.
- `TL1A_NOPLOTS` (`1` to disable) — skip matplotlib/seaborn figure rendering.
- `TL1A_STRICT` (`1` to enforce) — fail build if validation guardrails are exceeded.

## 2. Repository Map
- `report.py` — single entry point that synthesizes variants, runs all heuristics, writes CSVs/figures, and renders the Markdown report.
- `REPORT.md` — generated narrative; regenerate after any code/data edits. The timestamp at the top shows when it was created.
- `01_…16_.ipynb` — modular notebooks (QC, IMGT, developability, conjugation/DAR, detectability, manufacturability, immunogenicity, PK, structure, stress tests). Each notebook is self-contained and reads the local assets/CSV outputs.
- `00_env/README.md` — environment setup playbook (venv or conda). Note: this is the environment guide; the canonical README is the file you’re reading (repo root).
- `assets/` — exported FASTA (`assets/fabs.fasta`) and optional TNFSF family FASTA (`assets/tnfsf_family.fasta` if supplied).
- Root CSVs/PNGs — machine-readable tables (`developability.csv`, `dar.csv`, `manufacturability.csv`, `paratope.csv`, `immunogenicity.csv`, `master_table.csv`, `composite_ranking.csv`, etc.) and supporting figures (`fig_dar_p12.png`, `fig_dar_ge4.png`, `fig_dev_heatmap.png`, `fig_tbr_vs_kd.png`, `fig_lead_compare.png`).

## 3. Regenerating Outputs
- Default run (`python report.py`) executes:
  - CDR mutation enumeration (120 draw attempts) with glyco avoidance.
  - QC, developability, DAR, manufacturability, immunogenicity, paratope, cross-reactivity, and detectability heuristics.
  - Aggregated statistics, outlier detection, composite ranking, and Soluble TL1A sink summaries.
- All outputs are overwritten on each run; commit or back up downstream edits before re-running.
- Matplotlib/Seaborn plots are skipped automatically when the libraries are unavailable (`PLOTTING=False` graceful degrade).
- Guardrails: clones with `P_DAR_ge4 > 0.10` are listed in a Validation section of `REPORT.md`. Set `TL1A_STRICT=1` to make these hard failures.

## 4. Notebook Workflow Tips
- Run notebooks in numeric order for reproducibility; many reuse CSVs generated by `report.py` while adding exploratory visuals.
- Notebooks that require optional packages:
  - `11_rdkit_chelator.ipynb` → RDKit.
  - `12_visualization_py3Dmol.ipynb` → py3Dmol.
  - `13_sensitivity_SALib.ipynb` → SALib (already included in env instructions).
- `14_structure_modeling.ipynb` and `16_aggregation_stability.ipynb` accept user-supplied structure inputs once available; leave cells skipped if no PDBs are present.

## 5. Data Exports & Hand-offs
- `assets/fabs.fasta` contains every VH/VL pair (baseline + enumerated variants) for external assays or homology modeling.
- CSV tables align with sections in `REPORT.md`; share directly with CRO partners (e.g., developability package, conjugation plan, immunogenicity disclosure).
- `composite_ranking.csv` encodes the weighted score used in the report’s Top 3 summary.

## 6. Next Steps for Enhancements
- Replace heuristic DAR accessibility assumptions with structure-derived SASA (`lys_accessible_refined.csv`) when homology models are ready.
- Feed wet-lab measurements back into `lead_deep_compare.csv` to tighten the composite ranking weights.
- Extend `report.py` with CLI args (e.g., `--variants 200`, `--no-plots`) if higher-throughput sweeps become necessary.
 - Add a simple runner script (e.g., `make all`) to chain report regeneration and notebook execution if you prefer scripted end-to-end builds.
